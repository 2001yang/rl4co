{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving the Flexible Job-Shop Scheduling Problem (FJSP)\n",
    "\n",
    "The following notebook explains the FJSP and explains the solution construction process using an encoder-decoder architecture based on a Heterogeneous Graph Neural Network (HetGNN)\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/ai4co/rl4co/blob/main/examples/other/2-scheduling.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from rl4co.envs import FJSPEnv\n",
    "from rl4co.models.zoo.l2d import L2DModel\n",
    "from rl4co.models.zoo.l2d.policy import L2DPolicy\n",
    "from rl4co.models.zoo.l2d.decoder import L2DDecoder\n",
    "from rl4co.models.nn.graph.hgnn import HetGNNEncoder\n",
    "from rl4co.utils.trainer import RL4COTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_params = {\n",
    "  \"num_jobs\": 5,  # the total number of jobs\n",
    "  \"num_machines\": 5,  # the total number of machines that can process operations\n",
    "  \"min_ops_per_job\": 1,  # minimum number of operatios per job\n",
    "  \"max_ops_per_job\": 2,  # maximum number of operations per job\n",
    "  \"min_processing_time\": 1,  # the minimum time required for a machine to process an operation\n",
    "  \"max_processing_time\": 20,  # the maximum time required for a machine to process an operation\n",
    "  \"min_eligible_ma_per_op\": 1,  # the minimum number of machines capable to process an operation\n",
    "  \"max_eligible_ma_per_op\": 2,  # the maximum number of machines capable to process an operation\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = FJSPEnv(generator_params=generator_params)\n",
    "td = env.reset(batch_size=[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Problem\n",
    "\n",
    "Below we visualize the generated instance of the FJSP. Blue nodes correspond to machines, red nodes to operations and yellow nodes to jobs. A machine may process an operation if there exists an edge between the two. \n",
    "\n",
    "The thickness of the connection between a machine and an operation node specifies the processing time the respective machine needs to process the operation (thicker line := longer processing).\n",
    "\n",
    "Each operation belongs to exactly one job, where an edge between a job and an operation node indicates that the respective operation belongs to the job. The number above an operation-job edge specifies the precedence-order in which the operations of a job need to be processed. A job is done when all operations belonging to it are scheduled. The instance is solved when all jobs are fully scheduled.\n",
    "\n",
    "Also note that some operation nodes are not connected. These operation nodes are padded, so that all instances in a batch have the same number of operations (where we determine the maximum number of operations as num_jobs * max_ops_per_job). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Create a bipartite graph from the adjacency matrix\n",
    "G = nx.Graph()\n",
    "proc_times = td[\"proc_times\"].squeeze(0)\n",
    "job_ops_adj = td[\"job_ops_adj\"].squeeze(0)\n",
    "order = td[\"ops_sequence_order\"].squeeze(0) + 1\n",
    "\n",
    "num_machines, num_operations = proc_times.shape\n",
    "num_jobs = job_ops_adj.size(0)\n",
    "\n",
    "jobs = [f\"j{i+1}\" for i in range(num_jobs)]\n",
    "machines = [f\"m{i+1}\" for i in range(num_machines)]\n",
    "operations = [f\"o{i+1}\" for i in range(num_operations)]\n",
    "\n",
    "# Add nodes from each set\n",
    "G.add_nodes_from(machines, bipartite=0)\n",
    "G.add_nodes_from(operations, bipartite=1)\n",
    "G.add_nodes_from(jobs, bipartite=2)\n",
    "\n",
    "# Add edges based on the adjacency matrix\n",
    "for i in range(num_machines):\n",
    "    for j in range(num_operations):\n",
    "        edge_weigth = proc_times[i][j]\n",
    "        if edge_weigth != 0:\n",
    "            G.add_edge(f\"m{i+1}\", f\"o{j+1}\", weight=edge_weigth)\n",
    "\n",
    "\n",
    "# Add edges based on the adjacency matrix\n",
    "for i in range(num_jobs):\n",
    "    for j in range(num_operations):\n",
    "        edge_weigth = job_ops_adj[i][j]\n",
    "        if edge_weigth != 0:\n",
    "            G.add_edge(f\"j{i+1}\", f\"o{j+1}\", weight=3, label=order[j])\n",
    "\n",
    "\n",
    "widths = [x / 3 for x in nx.get_edge_attributes(G, 'weight').values()]\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "# Plot the graph\n",
    "\n",
    "machines = [n for n, d in G.nodes(data=True) if d['bipartite'] == 0]\n",
    "operations = [n for n, d in G.nodes(data=True) if d['bipartite'] == 1]\n",
    "jobs = [n for n, d in G.nodes(data=True) if d['bipartite'] == 2]\n",
    "\n",
    "pos = {}\n",
    "pos.update((node, (1, index)) for index, node in enumerate(machines))\n",
    "pos.update((node, (2, index)) for index, node in enumerate(operations))\n",
    "pos.update((node, (3, index)) for index, node in enumerate(jobs))\n",
    "\n",
    "edge_labels = {(u, v): d['label'].item() for u, v, d in G.edges(data=True) if d.get(\"label\") is not None}\n",
    "nx.draw_networkx_edge_labels(G, {k: (v[0]+.12, v[1]) for k,v in pos.items()}, edge_labels=edge_labels, rotate=False)\n",
    "\n",
    "nx.draw_networkx_nodes(G, pos, nodelist=machines, node_color='b', label=\"Machine\")\n",
    "nx.draw_networkx_nodes(G, pos, nodelist=operations, node_color='r', label=\"Operation\")\n",
    "nx.draw_networkx_nodes(G, pos, nodelist=jobs, node_color='y', label=\"jobs\")\n",
    "nx.draw_networkx_edges(G, pos, width=widths, alpha=0.6)\n",
    "\n",
    "plt.title('Visualization of the FJSP')\n",
    "plt.legend(bbox_to_anchor=(.95, 1.05))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Model to Solve the FJSP\n",
    "\n",
    "In the FJSP we typically encode Operations and Machines separately, since they pose different node types in a k-partite Graph. Therefore, the encoder for the FJSP returns two hidden representations, the first containing machine embeddings and the second containing operation embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets generate a more complex instance\n",
    "\n",
    "generator_params = {\n",
    "  \"num_jobs\": 10,  # the total number of jobs\n",
    "  \"num_machines\": 5,  # the total number of machines that can process operations\n",
    "  \"min_ops_per_job\": 4,  # minimum number of operatios per job\n",
    "  \"max_ops_per_job\": 6,  # maximum number of operations per job\n",
    "  \"min_processing_time\": 1,  # the minimum time required for a machine to process an operation\n",
    "  \"max_processing_time\": 20,  # the maximum time required for a machine to process an operation\n",
    "  \"min_eligible_ma_per_op\": 1,  # the minimum number of machines capable to process an operation\n",
    "  \"max_eligible_ma_per_op\": 5,  # the maximum number of machines capable to process an operation\n",
    "}\n",
    "\n",
    "env = FJSPEnv(generator_params=generator_params)\n",
    "td = env.reset(batch_size=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = HetGNNEncoder(embed_dim=32, num_layers=2)\n",
    "(ma_emb, op_emb), init = encoder(td)\n",
    "print(ma_emb.shape)\n",
    "print(op_emb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decoder return logits over a composite action-space of size (1 + num_jobs * num_machines), where each entry corresponds to a machine-job combination plus one **waiting**-operation. The selected action specifies, which job is processed next by which machine. To be more precise, the next operation of the selected job is processed. This operation can be retrieved from __td[\"next_op\"]__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next operation per job\n",
    "td[\"next_op\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = L2DDecoder(env_name=env.name, embed_dim=32)\n",
    "logits, mask = decoder(td, (ma_emb, op_emb), num_starts=0)\n",
    "# (1 + num_jobs * num_machines)\n",
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_step(td):\n",
    "    logits, mask = decoder(td, (ma_emb, op_emb), num_starts=0)\n",
    "    action = logits.masked_fill(~mask, -torch.inf).argmax(1)\n",
    "    td[\"action\"] = action\n",
    "    td = env.step(td)[\"next\"]\n",
    "    return td"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize solution construction\n",
    "\n",
    "Starting at $t=0$, the decoder uses the machine-operation embeddings of the encoder to decide which machine-**job**-combination to schedule next. Note, that due to the precedence relationship, the operations to be scheduled next are fixed per job. Therefore, it is sufficient to determine the next job to be scheduled, which significantly reduces the action space. \n",
    "\n",
    "After some operations have been scheduled, either all the machines are busy or all the jobs have been scheduled with their currently active operation. In this case, the environment transitions to a new time step $t$. The new $t$ will be equal to the first time step where a machine finishes an operation in the partial schedule. When an operation is finished, the machine that has processed it is immediately ready to process the next operation. Also, the next operation of the respective job can then be scheduled.\n",
    "\n",
    "The start time of an operation is always equal to the time step in which it is scheduled. The finish time of an operation is equal to its start time plus the processing time required by the machine on which it is being processed.\n",
    "\n",
    "The figure below visualises this process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.render(td, 0)\n",
    "# Update plot within a for loop\n",
    "while not td[\"done\"].all():\n",
    "    # Clear the previous output for the next iteration\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    td = make_step(td)\n",
    "    env.render(td, 0)\n",
    "    # Display updated plot\n",
    "    display(plt.gcf())\n",
    "    \n",
    "    # Pause for a moment to see the changes\n",
    "    time.sleep(.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    accelerator = \"gpu\"\n",
    "    batch_size = 256\n",
    "    train_data_size = 2_000\n",
    "    embed_dim = 128\n",
    "    num_encoder_layers = 4\n",
    "else:\n",
    "    accelerator = \"cpu\"\n",
    "    batch_size = 32\n",
    "    train_data_size = 1_000\n",
    "    embed_dim = 64\n",
    "    num_encoder_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Policy: neural network, in this case with encoder-decoder architecture\n",
    "policy = L2DPolicy(embed_dim=embed_dim, num_encoder_layers=num_encoder_layers, env_name=\"fjsp\")\n",
    "\n",
    "# Model: default is AM with REINFORCE and greedy rollout baseline\n",
    "model = L2DModel(env,\n",
    "                 policy=policy, \n",
    "                 baseline=\"rollout\",\n",
    "                 batch_size=batch_size,\n",
    "                 train_data_size=train_data_size,\n",
    "                 val_data_size=1_000,\n",
    "                 optimizer_kwargs={\"lr\": 1e-4})\n",
    "\n",
    "trainer = RL4COTrainer(\n",
    "    max_epochs=3,\n",
    "    accelerator=accelerator,\n",
    "    devices=1,\n",
    "    logger=None,\n",
    ")\n",
    "\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving the Job-Shop Scheduling Problem (JSSP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from rl4co.envs import JSSPEnv\n",
    "from rl4co.models.zoo.l2d.model import L2DPPOModel\n",
    "from rl4co.models.zoo.l2d.policy import L2DPolicy4PPO\n",
    "from torch.utils.data import DataLoader\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets generate a more complex instance\n",
    "\n",
    "generator_params = {\n",
    "  \"num_jobs\": 15,  # the total number of jobs\n",
    "  \"num_machines\": 15,  # the total number of machines that can process operations\n",
    "  \"min_processing_time\": 1,  # the minimum time required for a machine to process an operation\n",
    "  \"max_processing_time\": 99,  # the maximum time required for a machine to process an operation\n",
    "}\n",
    "\n",
    "env = JSSPEnv(\n",
    "    generator_params=generator_params, \n",
    "    _torchrl_mode=True, \n",
    "    stepwise_reward=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on synthetic data and test on Taillard benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Policy: neural network, in this case with encoder-decoder architecture\n",
    "policy = L2DPolicy4PPO(\n",
    "    embed_dim=embed_dim, \n",
    "    num_encoder_layers=num_encoder_layers, \n",
    "    env_name=\"jssp\",\n",
    "    het_emb=False\n",
    ")\n",
    "\n",
    "model = L2DPPOModel(\n",
    "    env=env,\n",
    "    policy=policy,\n",
    "    batch_size=batch_size,\n",
    "    train_data_size=train_data_size,\n",
    "    val_data_size=1_000,\n",
    "    optimizer_kwargs={\"lr\": 1e-4}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = \"last.ckpt\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "try:\n",
    "    model = L2DPPOModel.load_from_checkpoint(CHECKPOINT_PATH)\n",
    "except FileNotFoundError:\n",
    "\n",
    "    trainer = RL4COTrainer(\n",
    "        max_epochs=1,\n",
    "        accelerator=accelerator,\n",
    "        devices=1,\n",
    "        logger=None,\n",
    "    )\n",
    "\n",
    "    trainer.fit(model)\n",
    "finally:\n",
    "    model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Check if the folder exists\n",
    "if [ -d \"JSPLIB\" ]; then\n",
    "    echo \"Found JSPLIB\"\n",
    "else\n",
    "    echo \"Cloning JSPLIB\"\n",
    "    git clone https://github.com/tamy0612/JSPLIB.git\n",
    "fi\n",
    "\n",
    "exit 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_taillard_data(nj, nm):\n",
    "    fp = f\"taillard/{nj}x{nm}\"\n",
    "    if os.path.exists(fp):\n",
    "        pass\n",
    "    else:\n",
    "        os.makedirs(fp)\n",
    "        with open('JSPLib/instances.json', 'r') as file:\n",
    "            data = json.load(file)\n",
    "\n",
    "        instances = [x for x in data if \"ta\" in x[\"name\"] and x[\"jobs\"] == nj and x[\"machines\"] == nm]\n",
    "\n",
    "        for instance in instances:\n",
    "            os.popen(f\"cp JSPLIB/{instance['path']} {fp}/{instance['name']}.txt\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to taillard instances\n",
    "FILE_PATH = \"taillard/{nj}x{nm}\"\n",
    "\n",
    "results = {}\n",
    "instance_types = [(15, 15), (20, 15), (20, 20), (30, 15), (30, 20)]\n",
    "\n",
    "for instance_type in instance_types:\n",
    "    nj, nm = instance_type\n",
    "    prepare_taillard_data(nj, nm)\n",
    "    dataset = env.dataset(batch_size=[10], phase=\"test\", filename=FILE_PATH.format(nj=nj, nm=nm))\n",
    "    dl = DataLoader(dataset, batch_size=5, collate_fn=dataset.collate_fn)\n",
    "    rewards = []\n",
    "    \n",
    "    for batch in dl:\n",
    "        td = env.reset(batch).to(device)\n",
    "        # use policy.generate to avoid grad calculations which can lead to oom \n",
    "        out = model.policy.generate(td, env=env, phase=\"test\", decode_type=\"multistart_sampling\", num_starts=100, select_best=True)\n",
    "        rewards.append(out[\"reward\"])\n",
    "\n",
    "    reward = torch.cat(rewards, dim=0).mean().item()\n",
    "    results[instance_type] = reward\n",
    "\n",
    "    print(\"Done evaluating instance type %s with reward %s\" % (instance_type, reward))\n",
    "\n",
    "    # avoid ooms due to cache not being cleared \n",
    "    model.rb.empty()\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl4co_pypi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
